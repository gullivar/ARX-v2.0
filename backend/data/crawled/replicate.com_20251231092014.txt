Replicate - Run AI with an API Replicate is joining Cloudflare Replicate glyph Replicate wordmark Explore Pricing Enterprise Docs Blog Sign in Try for free Menu Explore Pricing Enterprise Docs Blog Sign in Try for free Compare models in the Playground Beta Run AI with an API . Run and fine-tune models. Deploy custom models. All with one line of code. Get started for free Node Python HTTP import Replicate from "replicate" ; const replicate = new Replicate ({ auth : process. env . REPLICATE_API_TOKEN }) const model = const input = { prompt : }; const [output] = await replicate. run (model, { input }); console . log (output); A poolside patio at sunset with vintage lounge chairs . black-forest-labs/flux-2-pro A soft armchair shaped like a peeled banana . google/nano-banana-pro A woman relaxing in a french bookstore . bytedance/seedream-4 A futuristic robot looking into the distance . black-forest-labs/flux-pro An abstract painting of a sunrise . black-forest-labs/flux-pro With Replicate you can Generate images Generate speech Generate music Restore images Large Language Models (LLMs) Generate videos from images Caption Images google / imagen-4-fast Use this fast version of Imagen 4 when speed and cost are more important than quality 3.1M runs Official bytedance / seedream-4 Unified text-to-image generation and precise single-sentence editing at up to 4K resolution 20M runs Official black-forest-labs / flux-1.1-pro Faster, better FLUX Pro. Text-to-image model with excellent image quality, prompt adherence, and output diversity. 65.7M runs Official ideogram-ai / ideogram-v3-turbo Turbo is the fastest and cheapest Ideogram v3. v3 creates images with stunning realism, creative designs, and consistent styles 5.7M runs Official qwen / qwen-image An image generation foundation model in the Qwen series that achieves significant advances in complex text rendering. 1.3M runs Official black-forest-labs / flux-schnell The fastest image generation model tailored for local development and personal use 581.6M runs Official fermatresearch / sdxl-controlnet-lora '''Last update: Now supports img2img.''' SDXL Canny controlnet with LoRA support. 985.7K runs google / imagen-4 Google's Imagen 4 flagship model 6.8M runs Official google / imagen-4-fast Use this fast version of Imagen 4 when speed and cost are more important than quality 3.1M runs Official bytedance / seedream-4 Unified text-to-image generation and precise single-sentence editing at up to 4K resolution 20M runs Official black-forest-labs / flux-1.1-pro Faster, better FLUX Pro. Text-to-image model with excellent image quality, prompt adherence, and output diversity. 65.7M runs Official ideogram-ai / ideogram-v3-turbo Turbo is the fastest and cheapest Ideogram v3. v3 creates images with stunning realism, creative designs, and consistent styles 5.7M runs Official qwen / qwen-image An image generation foundation model in the Qwen series that achieves significant advances in complex text rendering. 1.3M runs Official black-forest-labs / flux-schnell The fastest image generation model tailored for local development and personal use 581.6M runs Official fermatresearch / sdxl-controlnet-lora '''Last update: Now supports img2img.''' SDXL Canny controlnet with LoRA support. 985.7K runs google / imagen-4 Google's Imagen 4 flagship model 6.8M runs Official fermatresearch meta laion-ai vaibhavs10 prompthero stability-ai google-research jbilcke microsoft tomasmcm pollinations pixray tstramer mcai pagebrain lucataco zylim0702 fermatresearch laion-ai prompthero google-research microsoft pollinations tstramer pagebrain zylim0702 meta vaibhavs10 stability-ai jbilcke tomasmcm pixray mcai lucataco Thousands of models contributed by our community All the latest models are on Replicate. Theyâ€™re not just demos â€” they all actually work and have production-ready APIs. AI shouldnâ€™t be locked up inside academic papers and demos. Make it real by pushing it to Replicate. Explore models Push a model bytedance / seedance-1.5-pro A joint audio-video model that accurately follows complex instructions. 27.3K runs Official qwen / qwen-image-edit-2511 An enhanced version over Qwen-Image-Edit-2509, featuring multiple improvements including notably better consistency 28.4K runs Official openai / gpt-image-1.5 OpenAI's latest image generation model with better instruction following and adherence to prompts 225.9K runs Official black-forest-labs / flux-2-max The highest fidelity image model from Black Forest Labs 84K runs Official resemble-ai / chatterbox-turbo The fastest open source TTS model without sacrificing quality. 14.2K runs Official openai / gpt-5.2 The best model for coding and agentic tasks across industries 138K runs Official bytedance / seedance-1.5-pro A joint audio-video model that accurately follows complex instructions. 27.3K runs Official qwen / qwen-image-edit-2511 An enhanced version over Qwen-Image-Edit-2509, featuring multiple improvements including notably better consistency 28.4K runs Official openai / gpt-image-1.5 OpenAI's latest image generation model with better instruction following and adherence to prompts 225.9K runs Official black-forest-labs / flux-2-max The highest fidelity image model from Black Forest Labs 84K runs Official resemble-ai / chatterbox-turbo The fastest open source TTS model without sacrificing quality. 14.2K runs Official openai / gpt-5.2 The best model for coding and agentic tasks across industries 138K runs Official bytedance / seedream-4.5 Seedream 4.5: Upgraded Bytedance image model with stronger spatial understanding and world knowledge 855K runs Official prunaai / z-image-turbo Z-Image Turbo is a super fast text-to-image model of 6B parameters developed by Tongyi-MAI. 3.3M runs Official google / gemini-3-pro Google's most advanced reasoning Gemini model 84.9K runs Official google / nano-banana-pro Google's state of the art image generation and editing model ðŸŒðŸŒ 6.4M runs Official google / veo-3.1 New and improved version of Veo 3, with higher-fidelity video, context-aware audio, reference image and last frame support 238.4K runs Official philz1337x / crystal-upscaler High-precision image upscaler optimized for portraits, faces and products. One of the upscale modes powered by Clarity AI. X:https://x.com/philz1337x 293.5K runs Official bytedance / seedream-4.5 Seedream 4.5: Upgraded Bytedance image model with stronger spatial understanding and world knowledge 855K runs Official prunaai / z-image-turbo Z-Image Turbo is a super fast text-to-image model of 6B parameters developed by Tongyi-MAI. 3.3M runs Official google / gemini-3-pro Google's most advanced reasoning Gemini model 84.9K runs Official google / nano-banana-pro Google's state of the art image generation and editing model ðŸŒðŸŒ 6.4M runs Official google / veo-3.1 New and improved version of Veo 3, with higher-fidelity video, context-aware audio, reference image and last frame support 238.4K runs Official philz1337x / crystal-upscaler High-precision image upscaler optimized for portraits, faces and products. One of the upscale modes powered by Clarity AI. X:https://x.com/philz1337x 293.5K runs Official How it works You can get started with any model with just one line of code. But as you do more complex things, you can fine-tune models or deploy your own custom code. Run models Our community has already published thousands of models that are ready to use in production. You can run these with one line of code. Explore models import replicate output = replicate.run( "black-forest-labs/flux-dev" , input ={ "aspect_ratio" : "1:1" , "num_outputs" : 1 , "output_format" : "jpg" , "output_quality" : 80 , "prompt" : "An astronaut riding a rainbow unicorn, cinematic, dramatic" , } ) print (output) Fine-tune models with your own data You can improve models with your own data to create new models that are better suited to specific tasks. Image models like SDXL can generate images of a particular person, object, or style. Fine-tune image models Train a model: training = replicate.trainings.create( destination= "mattrothenberg/drone-art" version= "ostris/flux-dev-lora-trainer:e440909d3512c31646ee2e0c7d6f6f4923224863a6a10c494606e79fb5844497" , input ={ "steps" : 1000 , "input_images" : https://example.com/images.zip , "trigger_word" : "TOK" , }, ) This will result in a new model: mattrothenberg / drone-art Fantastical images of drones on land and in the sky 0 runs mattrothenberg / drone-art Fantastical images of drones on land and in the sky 0 runs Then, you can run it with one line of code: output = replicate.run( "mattrothenberg/drone-art:abcde1234..." , input ={ "prompt" : "a photo of TOK forming a rainbow in the sky" }), ) Deploy custom models You arenâ€™t limited to the models on Replicate: you can deploy your own custom models using Cog , our open-source tool for packaging machine learning models. Cog takes care of generating an API server and deploying it on a big cluster in the cloud. We scale up and down to handle demand, and you only pay for the compute that you use. Learn more First, define the environment your model runs in with cog.yaml: build: gpu: true system_packages: - "libgl1-mesa-glx" - "libglib2.0-0" python_version: "3.10" python_packages: - "torch==1.13.1" predict: "predict.py:Predictor" Next, define how predictions are run on your model with predict.py: from cog import BasePredictor, Input, Path import torch class Predictor ( BasePredictor ): def setup ( self ): """Load the model into memory to make running multiple predictions efficient""" self .model = torch.load( "./weights.pth" ) # The arguments and types the model takes as input def predict ( self, image: Path = Input(description= "Grayscale input image" ) ) -> Path: """Run a single prediction on the model""" processed_image = preprocess(image) output = self .model(processed_image) return postprocess(output) Scale on Replicate Thousands of businesses are building their AI products on Replicate. Your team can deploy an AI feature in a day and scale to millions of users, without having to be machine learning experts. Learn more about our enterprise plans Automatic scale If you get a ton of traffic, Replicate scales up automatically to handle the demand. If you don't get any traffic, we scale down to zero and don't charge you a thing. CPU $0.000100 /sec Nvidia T4 GPU $0.000225 /sec Nvidia L40S GPU $0.000975 /sec 2x Nvidia L40S GPU $0.001950 /sec Nvidia A100 (80GB) GPU $0.001400 /sec 8x Nvidia A100 (80GB) GPU $0.011200 /sec Learn more about pricing Pay for what you use Replicate only bills you for how long your code is running. You don't pay for expensive GPUs when you're not using them. Forget about infrastructure Deploying machine learning models at scale is hard. If you've tried, you know. API servers, weird dependencies, enormous model weights, CUDA, GPUs, batching. Prediction throughput (requests per second) Logging & monitoring Metrics let you keep an eye on how your models are performing, and logs let you zoom in on particular predictions to debug how your model is behaving. Replicate logo Imagine what you can build Autonomous Robots Zero-shot autonomous robots with open source models Paint with AI An iPad app that lets you paint with AI emojis.sh AI Emojis Never Gonna Give You Up Video fine tunes on Replicate Language Model CLI Language model command line interface Imagine Autonomous Robots Zero-shot autonomous robots with open source models what you Paint with AI An iPad app that lets you paint with AI can emojis.sh AI Emojis Never Gonna Give You Up Video fine tunes on Replicate build. Language Model CLI Language model command line interface With Replicate and tools like Next.js and Vercel, you can wake up with an idea and watch it hit the front page of Hacker News by the time you go to bed. Get started Replicate glyph Replicate wordmark Product Explore Playground (beta) Pricing Docs Blog Changelog Community Discord X GitHub Company Home About Changelog Join us Terms Privacy Status Support