Groq is fast, low cost inference. skip to content Groq Platform Arrow pointing down GroqCloud LPU Architecture See Pricing Solutions Arrow pointing down Industries & Use Cases Customer Stories Demos Learn Arrow pointing down Blog Changelog Whitepapers Subscribe Pricing About Arrow pointing down About Groq Newsroom Careers at Groq Contact Us Developers Arrow pointing down Free API key Community Docs Enterprises Start Building Menu Toggle Main Navigation Close icon Close mobile navigation Platform Arrow pointing down GroqCloud LPU Architecture See Pricing Solutions Arrow pointing down Industries & Use Cases Customer Stories Demos Learn Arrow pointing down Blog Changelog Whitepapers Subscribe Pricing About Arrow pointing down About Groq Newsroom Careers at Groq Contact Us Developers Arrow pointing down Free API key Community Docs Enterprises Groq Community Discord Twitter YouTube Thread LinkedIn Instagram Inference is Fuel for AI Groq delivers fast, low cost inference that doesn’t flake when things get real. Get Started Speed at a winning cost The McLaren F1 Team chooses Groq for inference globally. The Groq LPU LPU built for inference, exceptional speed and affordability at scale. 3m developers and teams Close Try the speed of Groq... Born for this. Literally. To deliver different results, you need a different stack. Others rely on GPUs alone. Our edge? Custom silicon. Groq pioneered the LPU in 2016, the first chip purpose-built for inference. Every design choice focuses on keeping intelligence fast and affordable. Learn More Benchmarks don’t ship. Workloads do. Instant intelligence. Deployed worldwide. Inference works best when it’s local. Groq’s LPU-based stack runs in data centers across the world to deliver low-latency responses from the most intelligent models. View Models The LPU is the cartridge. GroqCloud is the console. Devs trust GroqCloud for inference that stays smart, fast and affordable. View Pricing What inference provider are you using or considering using to access models? Source: Artificial Analysis AI Adoption Survey 2025 Partnership Spotlight The McLaren Formula 1 Team chooses Groq for inference. The McLaren F1 Team is fueled by decision-making, analysis, development and real-time insights. So the McLaren F1 Team chose Groq. Read More Don’t take our word for it. Proof from the people shipping. Read Customer Stories If we have things where performance matters more, we come to Groq - you deliver real, working solutions, not just buzzwords. Kevin Scott, CTO, PGA of America We optimized our infrastructure to its limits – but the breakthrough came with GroqCloud. Overnight, our chat speed surged 7.41x while costs fell by 89%. I was stunned. So, we tripled our token consumption. We simply can’t get enough. Nicolas Bustamante, CEO, Fintool Groq has created immense savings and reduced so much overhead for us. We’ve been able to keep costs for our main offerings incredibly low, helping keep our premium plan at a reasonable price for students of all backgrounds. Abhigyan Arya, CTO, Opennote If we have things where performance matters more, we come to Groq - you deliver real, working solutions, not just buzzwords. Kevin Scott, CTO, PGA of America We optimized our infrastructure to its limits – but the breakthrough came with GroqCloud. Overnight, our chat speed surged 7.41x while costs fell by 89%. I was stunned. So, we tripled our token consumption. We simply can’t get enough. Nicolas Bustamante, CEO, Fintool Groq has created immense savings and reduced so much overhead for us. We’ve been able to keep costs for our main offerings incredibly low, helping keep our premium plan at a reasonable price for students of all backgrounds. Abhigyan Arya, CTO, Opennote SWITCH FASTER THAN YOU CAN READ THIS. OpenAI compatible in just two lines. Start Now python javascript 1 import os 2 import openai 3 4 client = openai.OpenAI( 5 base_url= "https://api.groq.com/openai/v1" , 6 api_key=os.environ.get( "GROQ_API_KEY" ) 7 ) Copy News Featured September 17, 2025 Groq Raises $750 Million as Inference Demand Surges Arrow icon pointing right August 5, 2025 Day Zero Support for OpenAI Open Models Arrow icon pointing right May 27, 2025 From Speed to Scale: How Groq Is Optimized for MoE & Other Large Models Arrow icon pointing right Build Fast Seamlessly integrate Groq starting with just a few lines of code Try Groq for Free Groq Groq was established in 2016 for one thing: inference. Groq Footer Links Platform & Solutions GroqCloud LPU Architecture See Pricing Customer Stories Demos Enterprise Inquiry Learn Blog Whitepapers Subscribe About About Groq Newsroom Careers at Groq Contact Us Developers Free API key Community Docs Terms & Policies Website Terms of Use Privacy Policy Groq Trust Center Cookie Notice Groq Privacy Portal GroqCloud Terms Groq Services Agreement Security Trademark Policy Photography and Filming Policy © 2025 Groq, Inc. , All rights reserved. Groq Community Discord Twitter YouTube Thread LinkedIn Instagram