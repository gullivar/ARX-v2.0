Skip to content
Cursor
Features
Enterprise
Pricing
Resources
‚Üì
Sign in
Download
Built to make you extraordinarily productive, Cursor is the best way to code with AI.
Download for macOS
‚§ì
This element contains an interactive demo for sighted users showing multiple Cursor interfaces: the IDE with AI-powered coding assistance, the CLI with command-line assistance. The interfaces are displayed over a scenic painted landscape wallpaper, giving the demo an artistic backdrop.
Cursor
Get Cursor
IN PROGRESS 3
Enterprise Order Management System
Generating
Analyze Tab vs Agent Usage Patterns
Generating
Fix PR Comments Fetching Issue
Generating
READY FOR REVIEW 3
PyTorch MNIST Experiments
now
+162
-37
¬∑
Done, configurable MNIST experiment framework with AMP and reports. ‚Ä¢ **Training**: AMP, train/val split, cosine schedu
Set up Cursor Rules for Dashboard
30m
+37
-0
¬∑
Set up Cursor Rules for Dashboard
Bioinformatics Tools
45m
+135
-21
¬∑
Bioinformatics Tools
train_model.py
run_experiment.py
config.yaml
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torch.utils.data import DataLoader, random_split
from torchvision import datasets
from torchvision import datasets, transforms
from tqdm import tqdm
import yaml
from pathlib import Path
import json

def get_dataloaders(batch_size=64):
  transform = transforms.Compose([transforms.ToTensor()])
  train = datasets.MNIST(root="data", train=True, download=True, transform=transform)
  test = datasets.MNIST(root="data", train=False, download=True, transform=transform)
  return DataLoader(train, batch_size=batch_size, shuffle=True), DataLoader(test, batch_size=batch_size)
def load_config(config_path="experiments/config.yaml"):
  with open(config_path) as f:
    return yaml.safe_load(f)

def get_dataloaders(config):
  transform_list = [transforms.ToTensor()]
  if config['data'].get('normalize', True):
    transform_list.append(transforms.Normalize((0.1307,), (0.3081,)))
  
  if config['data']['augmentation'].get('random_rotation'):
    transform_list.append(transforms.RandomRotation(
      config['data']['augmentation']['random_rotation']
    ))
  
  transform = transforms.Compose(transform_list)
  
  full_train = datasets.MNIST(root="data", train=True, download=True, transform=transform)
  train_size = int(0.8 * len(full_train))
  val_size = len(full_train) - train_size
  train_dataset, val_dataset = random_split(full_train, [train_size, val_size])
  
  test_dataset = datasets.MNIST(root="data", train=False, download=True, transform=transform)
  
  batch_size = config['training']['batch_size']
  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
  val_loader = DataLoader(val_dataset, batch_size=batch_size)
  test_loader = DataLoader(test_dataset, batch_size=batch_size)
  
  return train_loader, val_loader, test_loader

class MLP(nn.Module):
  def __init__(self, hidden=128):
  def __init__(self, config):
    super().__init__()
    hidden = config['model']['hidden_size']
    dropout = config['model']['dropout']
    
    self.net = nn.Sequential(
      nn.Flatten(),
      nn.Linear(28*28, hidden),
      nn.ReLU(),
      nn.Dropout(dropout),
      nn.Linear(hidden, hidden // 2),
      nn.ReLU(),
      nn.Dropout(dropout),
      nn.Linear(hidden, 10),
      nn.Linear(hidden // 2, 10),
    )

  def forward(self, x):
    return self.net(x)

def train_model(epochs=1, lr=1e-3, device=None):
  device = device or ("cuda" if torch.cuda.is_available() else "cpu")
  model = MLP().to(device)
  opt = torch.optim.Adam(model.parameters(), lr=lr)
def train_model(config_path="experiments/config.yaml"):
  config = load_config(config_path)
  device = "cuda" if torch.cuda.is_available() and config['training']['use_amp'] else "cpu"
  
  torch.manual_seed(42)
  if device == "cuda":
    torch.cuda.manual_seed_all(42)
  
  model = MLP(config).to(device)
  opt = torch.optim.Adam(
    model.parameters(), 
    lr=config['training']['learning_rate'],
    weight_decay=config['training']['weight_decay']
  )
  loss_fn = nn.CrossEntropyLoss()
  train_loader, _ = get_dataloaders()
+  # Seed for reproducibility
+  torch.manual_seed(42)
+  if device == "cuda":
+    torch.cuda.manual_seed_all(42)
+  # AMP + Scheduler
+  scaler = torch.cuda.amp.GradScaler(enabled=(device=="cuda"))
+  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs)
  model.train()
  for epoch in range(epochs):
    total, correct = 0, 0
    for x, y in tqdm(train_loader, desc=f"epoch {epoch+1}"):
  
  train_loader, val_loader, test_loader = get_dataloaders(config)
  
  use_amp = config['training']['use_amp'] and device == "cuda"
  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)
  
  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
    opt, T_max=config['training']['epochs']
  )
  
  history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}
  
  for epoch in range(config['training']['epochs']):
    model.train()
    train_loss, train_correct, train_total = 0, 0, 0
    
    for x, y in tqdm(train_loader, desc=f"Epoch {epoch+1}/{config['training']['epochs']}"):
      x, y = x.to(device), y.to(device)
      opt.zero_grad(set_to_none=True)
      logits = model(x)
      loss = loss_fn(logits, y)
      loss.backward()
      opt.step()
      with torch.cuda.amp.autocast(enabled=use_amp):
        logits = model(x)
        loss = loss_fn(logits, y)
      
      scaler.scale(loss).backward()
      
      if config['training']['gradient_clip'] > 0:
        scaler.unscale_(opt)
+      torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        torch.nn.utils.clip_grad_norm_(model.parameters(), config['training']['gradient_clip'])
      
      scaler.step(opt)
      scaler.update()
+      preds = logits.argmax(dim=1)
+      total += y.size(0)
+      correct += (preds == y).sum().item()
+    acc = correct / max(1, total)
      
      train_loss += loss.item() * x.size(0)
      train_correct += (logits.argmax(1) == y).sum().item()
      train_total += x.size(0)
    
    model.eval()
    val_loss, val_correct, val_total = 0, 0, 0
    
    with torch.no_grad():
      for x, y in val_loader:
        x, y = x.to(device), y.to(device)
        logits = model(x)
        loss = loss_fn(logits, y)
        
        val_loss += loss.item() * x.size(0)
        val_correct += (logits.argmax(1) == y).sum().item()
        val_total += x.size(0)
    
    train_loss = train_loss / train_total
    train_acc = train_correct / train_total
    val_loss = val_loss / val_total
    val_acc = val_correct / val_total
    
    history['train_loss'].append(train_loss)
    history['train_acc'].append(train_acc)
    history['val_loss'].append(val_loss)
    history['val_acc'].append(val_acc)
    
    print(f"Epoch {epoch+1}: train_loss={train_loss:.4f}, train_acc={train_acc:.3f}, "
          f"val_loss={val_loss:.4f}, val_acc={val_acc:.3f}")
    
    scheduler.step()
+    print(f"epoch {epoch+1}: acc={acc:.3f}")
  return model`,
    
    if (epoch + 1) % 5 == 0:
      checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': opt.state_dict(),
        'scheduler_state_dict': scheduler.state_dict(),
        'history': history,
        'config': config
      }
      Path('checkpoints').mkdir(exist_ok=True)
      torch.save(checkpoint, f'checkpoints/model_epoch_{epoch+1}.pt')
  
  Path('results').mkdir(exist_ok=True)
  with open('results/training_history.json', 'w') as f:
    json.dump(history, f, indent=2)
  
  return model, history, test_loader
PyTorch MNIST Experiments
Add mixed precision training, learning rate scheduling, and proper validation. Also create an experiment config system so I can easily run different hyperparameter settings.
Thought
10s
Searched
PyTorch mixed precision training best practices
Read
notebooks/train_model.py (current implementation)
I'll enhance your MNIST trainer with a complete experiment framework including mixed precision, validation splitting, and proper configuration management. Let me start by rewriting the training module:
train_model.py+156-34
Now let me update the evaluation module to save results and generate a detailed report:
evaluation.py+24-6
Let me create a command-line runner script to make experiments easy to execute:
run_experiment.py+29
Done, configurable MNIST experiment framework with AMP and reports.
‚Ä¢
Training: AMP, train/val split, cosine schedule, gradient clipping, checkpoints
‚Ä¢
Experimentation: YAML config, saved history, confusion matrix + classification report, CLI runner
Agent
GPT-5
cursor-agent
Get CLI
Cursor Agent
~/Repos/ml-research-notebook
PyTorch MNIST Experiments
Add mixed precision training, learning rate scheduling, and proper validation. Also create an experiment config system so I can easily run different hyperparameter settings.
‚¨¢
Thought 10s
‚¨¢
Searched PyTorch mixed precision training best practices
‚¨¢
Read notebooks/train_model.py (current implementation)
I'll enhance your MNIST trainer with a complete experiment framework including mixed precision, validation splitting, and proper configuration management. Let me start by rewriting the training module:
train_model.py+156-34
Now let me update the evaluation module to save results and generate a detailed report:
evaluation.py+24-6
‚Üí
ctrl+c to stop
GPT-5.2
/ for commands ¬∑ @ for files
Trusted every day by millions of professional developers.
Agent turns ideas into code
A human-AI programmer, orders of magnitude more effective than any developer alone.
Learn about Agent ‚Üí
This element contains an interactive demo for sighted users. It's a demonstration of Cursor's IDE showing AI-powered coding assistance features. The interface is displayed over a scenic painted landscape wallpaper, giving the demo an artistic backdrop.
Cursor
Get Cursor
IN PROGRESS 4
Enterprise Order Management System
Generating
Analyze Tab vs Agent Usage Patterns
Generating
PyTorch MNIST Experiments
Generating
Fix PR Comments Fetching Issue
Generating
READY FOR REVIEW 2
Set up Cursor Rules for Dashboard
30m
+37
-0
¬∑
Set up Cursor Rules for Dashboard
Bioinformatics Tools
45m
+135
-21
¬∑
Bioinformatics Tools
Analyze Tab vs Agent Usage Patterns
Help me understand how teams split their focus between the tab view and the agents panel across our workspaces.
Agent
GPT-5
Magically accurate autocomplete
Our custom Tab model predicts your next action with striking speed and precision.
Learn about Tab ‚Üí
This element contains an interactive demo for sighted users. It's a demonstration of Cursor's IDE showing AI-powered coding assistance features. The interface is displayed over a scenic painted landscape wallpaper, giving the demo an artistic backdrop.
Cursor
Get Cursor
Dashboard.tsx
SupportChat.tsx
"use client";

import React, { useState } from "react";
import Navigation from "./Navigation";
import SupportChat from "./SupportChat";

export default function Dashboard() {


  return (
    <div className="flex h-[600px] border rounded-lg overflow-hidden">
      <div className="w-64 border-r">
      </div>
      <div className="w-80 border-l">
        <SupportChat />
      </div>
    </div>
  );
}
  const [activeTab, setActiveTab] = useState("support");
Everywhere software gets built
Cursor is in GitHub reviewing your PRs, a teammate in Slack, and anywhere else you work.
Learn about Cursor's ecosystem ‚Üí
This element contains an interactive demo for sighted users showing multiple Cursor interfaces: Slack integration for team communication, GitHub integration for code review and debugging. The interfaces are displayed over a scenic painted landscape wallpaper, giving the demo an artistic backdrop.
Slack
Get Cursor for Slack
#ask-cursor
8 members
dylan
9/16/2025
small thing but would be really good to have anchor links on the website for releases
4
replies
dylan
9/16/2025
wanna be able to go to cursor.com/changelog#1.0 to see 1.0 changelog
eric
9/16/2025
checks out
@cursor can you take a stab?
Cursor
APP
9/16/2025
I implemented direct linking for changelog entries and updated Node.js version constraints across the project to improve compatibility and maintainability.
View PR
Open in Cursor
Open in Web
dylan
9/16/2025
Nice @eric can you take a look?
GitHub Pull Request
Get BugBot
cursor
bot
reviewed
1m ago
src/vs/workbench/composer/browser/components/ComposerUnifiedDropdown.tsx
3292
-  {selectedMode().keybinding}
3293
+  {composerOpenModeToggleKeybinding}
cursor
bot
1m ago
Bug: Function Returns Object Instead of String (Logic bug)
The composerOpenModeToggleKeybinding is a function that needs to be called to get its value. Using it directly causes the keybinding display condition to always be truthy.
Fix in Cursor
Fix in Web
The new way to build software.

It was night and day from one batch to another, adoption went from single digits to over 80%. It just spread like wildfire, all the best builders were using Cursor.

Diana Hu
General Partner, Y Combinator

The most useful AI tool that I currently pay for, hands down, is Cursor. It's fast, autocompletes when and where you need it to, handles brackets properly, sensible keyboard shortcuts, bring-your-own-model... everything is well put together.

shadcn
Creator of shadcn/ui

The best LLM applications have an autonomy slider: you control how much independence to give the AI. In Cursor, you can do Tab completion, Cmd+K for targeted edits, or you can let it rip with the full autonomy agentic version.

Andrej Karpathy
CEO, Eureka Labs

Cursor quickly grew from hundreds to thousands of extremely enthusiastic Stripe employees. We spend more on R&D and software creation than any other undertaking, and there's significant economic outcomes when making that process more efficient and productive.

Patrick Collison
Co‚ÄëFounder & CEO, Stripe

It's official. 

I hate vibe coding. 
I love Cursor tab coding. 

It's wild.

ThePrimeagen
@ThePrimeagen

It's definitely becoming more fun to be a programmer. It's less about digging through pages and more about what you want to happen. We are at the 1% of what's possible, and it's in interactive experiences like Cursor where models like GPT-5 shine brightest.

Greg Brockman
President, OpenAI
Stay on the frontier
Access the best models
Choose between every cutting-edge model from OpenAI, Anthropic, Gemini, and xAI.
Explore models ‚Üó
Auto
Suggested
Composer 1
GPT-5
High Fast
Claude Sonnet 4.5
‚úì
Claude Opus 4.5
Gemini 3 Pro
Grok Code
Complete codebase understanding
Cursor learns how your codebase works, no matter the scale or complexity.
Learn about codebase indexing ‚Üó
Where are these menu label colors defined?
Grepped
Choose a model
Searching
Develop enduring software
Trusted by over half of the Fortune 500 to accelerate development, securely and at scale.
Explore enterprise ‚Üí
Changelog
2.3
Dec 22, 2025

Layout Customization and Stability Improvements

Dec 18, 2025

Enterprise Insights, Billing Groups, Service Accounts, and Improved Security Controls

2.2
Dec 10, 2025

Debug Mode, Plan Mode Improvements, Multi-Agent Judging, and Pinned Chats

2.1
Nov 21, 2025

Improved Plan Mode, AI Code Review in Editor, and Instant Grep

See what's new in Cursor ‚Üí
Cursor is an applied team focused on building the future of coding.
Join us
‚Üí
Recent highlights

Introducing Cursor 2.0 and Composer

A new interface and our first coding model, both purpose-built for working with agents.

Product¬†¬∑¬†
Oct 29, 2025

Improving Cursor Tab with online RL

Our new Tab model makes 21% fewer suggestions while having 28% higher accept rate.

Research¬†¬∑¬†
Sep 12, 2025

1.5x faster MoE training with custom MXFP8 kernels

Achieving a 3.5x MoE layer speedup with a complete rebuild for Blackwell GPUs.

Research¬†¬∑¬†
Aug 29, 2025
View more posts ‚Üí
Try Cursor now.
Download for macOS
‚§ì
Product
Features
Enterprise
Web Agents
Bugbot
CLI
Pricing
Resources
Download
Changelog
Docs¬†‚Üó
Learn¬†‚Üó
Forum¬†‚Üó
Status¬†‚Üó
Company
Careers
Blog
Community
Workshops
Students
Brand
Legal
Terms of Service
Privacy Policy
Data Use
Security
Connect
X¬†‚Üó
LinkedIn¬†‚Üó
YouTube¬†‚Üó
¬© 2025 Cursor
üõ° SOC 2 Certified
üñ•
‚òâ
‚òæ
üåê
English
‚Üì